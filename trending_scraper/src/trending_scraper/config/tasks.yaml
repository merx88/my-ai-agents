
# ===== Collect trending keywords from each trending site ===== #

collect_signal_trending:
  description: >
    Scrape only the child elements that appear to be real-time trending in the real-time trend area (<section class="container">) from the Signal site (https://signal.bz/) and save them as a markdown file (output/signal.md). If the area does not exist, freely extract what appears to be real-time trending keywords.
  expected_output: >
    A markdown file (output/signal.md) containing only the numbered real-time trending keywords from the Signal real-time trend area.
  agent: signal_trending_scraper

collect_namuwiki_trending:
  description: >
    Scrape the titles of each post from the NamuWiki trending channel (https://arca.live/b/namuhotnow) and save them as a markdown file (output/namuwiki.md). (The NamuWiki trending channel is a board that brings NamuWiki's trending keywords and explains the reasons.)
  expected_output: >
    A markdown file (output/namuwiki.md) containing only the titles of posts from the NamuWiki trending channel. The top of the markdown file should include the following phrase: "The following words are from the NamuWiki trending channel and are currently real-time trending keywords."
  agent: namuwiki_trending_scraper

collect_x_trending:
  description: >
    From getdaytrends (https://getdaytrends.com/ko/korea/), a site that shows X (Twitter) trends, extract keywords from the area containing X trend keywords (<div id="trends">). Extract not only current trends but also all keywords from the past 24 hours. Then save them as a markdown file (output/x.md). If the area does not exist, freely extract what appears to be real-time trending keywords. (X is the same site as Twitter.)
  expected_output: >
    A markdown file (output/x.md) containing only the numbered real-time trending keywords from X.
  agent: x_trending_crawler

collect_google_trending:
  description: >
    From Google Trends (e.g., https://trends.google.com/trending?geo=KR&hours=24), scrape only the child elements that appear to be real-time trending in the area (<table class="enOdEe-wZVHld-zg7Cn">) and save them as a markdown file (output/google.md). If the area does not exist, freely extract what appears to be real-time trending keywords.
  expected_output: >
    A markdown file (output/google.md) containing only the numbered real-time trending keywords from the Google real-time trend area.
  agent: google_trending_scraper

# ===== Trend Organization ===== #

organize_trending:
  description: >
    Gather the trend keyword markdown files (output/signal.md, output/namuwiki.md, output/x.md, output/google.md) collected from each service (Signal, NamuWiki, X, Google) and organize them for easy viewing. Clearly separate each service by section so it is clear which site each keyword came from.
  expected_output: >
    A single markdown file (output/scrapped_site.md) with trend keywords organized by service.
    Example:
    ### Signal Trends
    1. Keyword1
    2. Keyword2
    ...
    ### X Trends
    1. KeywordA
    2. KeywordB
    ...
  agent: trending_organizer

# ===== Trend Cross-Validation and Final Selection ===== #

cross_validate_trending:
  description: >
    Analyze the organized trend keyword data (from multiple services such as Signal, NamuWiki, X, and Google).
    Identify the Top 10 keywords that are considered 'real' trends â€” those mentioned across multiple services.
    For each keyword, summarize the reason for its selection (e.g., mentioned on 3 sites).
    Save the final result to `final.py` in the following format:

    result = [
      (1, "Keyword", "Reason for selection"),
      (2, "Another Keyword", "Another reason"),
      ...
    ]

  expected_output: >
    A Python list of 10 tuples in the format: [(rank, keyword, reason), ...].

    Each tuple should contain:
      - rank: integer (1 to 10)
      - keyword: string
      - reason: string (e.g., "Mentioned on Signal, NamuWiki, and X")

    The final result must be saved to `final.py` as a variable assignment:
    result = [ ... ]
  agent: cross_validation_agent


# ===== Notion Upload ===== #

# upload_to_notion:
#   description: >
#     Upload the contents of the final trend report (report.md) to a Notion page. The markdown content should be converted to the specified format and automatically posted via the Notion API. (The Notion API Key and Page ID must be set via environment variables.)
#   expected_output: >
#     A message confirming that the contents of the final trend report (report.md) have been successfully uploaded to the Notion page. Example: "Successfully uploaded to Notion page: [page URL]"
#   agent: notion_uploader